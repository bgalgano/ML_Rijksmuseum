{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import datetime\n",
    "import tensorflow_addons as tfa \n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_rijksdata\n",
    "MIN_NUM_ARTWORK = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = '/Users/erebor/Downloads/out_img'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erebor/repos/ML_Rijksmuseum/read_rijksdata.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  names = pd.read_csv(names_file,delimiter = '/t',header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |███████████████████████████████████████-| 112038/112039 \n",
      "\n",
      "Dataset loaded!\n",
      "images shape: (29703, 56, 56, 3)\n",
      "labels shape: (29703,)\n",
      "labels (one-hot): (29703, 50)\n",
      "names shape: (29703, 1)\n"
     ]
    }
   ],
   "source": [
    "images, labels_onehot, labels, names = read_rijksdata.load_data(MIN_NUM_ARTWORK=MIN_NUM_ARTWORK,\n",
    "                                                 img_folder =img_folder,\n",
    "                                                 labels_file='labels.txt',\n",
    "                                                 names_file='names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# number of unique artists: 50\n"
     ]
    }
   ],
   "source": [
    "print('# number of unique artists:', len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of classes: 50\n",
      "Min # of artworks for all artists: 303\n",
      "Min # of artworks specified: 300\n"
     ]
    }
   ],
   "source": [
    "classes = len(list(set(labels)))\n",
    "print('# of classes:',classes)\n",
    "\n",
    "counts = pd.DataFrame(labels).value_counts()\n",
    "print('Min # of artworks for all artists:',min(counts))\n",
    "print('Min # of artworks specified:',MIN_NUM_ARTWORK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (56,56,3)\n",
    "enet_kwargs = {'include_top':False,\n",
    "               'weights':'imagenet',\n",
    "               'input_tensor':None,\n",
    "               'input_shape':input_shape,\n",
    "               'pooling':None,\n",
    "               'classes':classes,\n",
    "               'classifier_activation':'softmax'}\n",
    "enet_base = tf.keras.applications.efficientnet.EfficientNetB7(**enet_kwargs)\n",
    "enet_base.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enet_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pre-trained model as base\n",
    "enet = tf.keras.models.Sequential()\n",
    "enet.add(enet_base)\n",
    "\n",
    "enet.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "enet.add(tf.keras.layers.Dropout(rate=0.01))\n",
    "enet.add(tf.keras.layers.Dense(classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb7 (Functional)  (None, 2, 2, 2560)        64097687  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                128050    \n",
      "=================================================================\n",
      "Total params: 64,225,737\n",
      "Trainable params: 63,915,010\n",
      "Non-trainable params: 310,727\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False,\n",
    "                                               label_smoothing=0.0,\n",
    "                                               name='categorical_crossentropy')\n",
    "\n",
    "# metrics\n",
    "\n",
    "TopKs = []\n",
    "for k in [1,5,10,20]:\n",
    "    TopK = tf.keras.metrics.TopKCategoricalAccuracy(k=k, name='top_{}'.format(k))\n",
    "    TopKs.append(TopK)\n",
    "metrics = [\"acc\"]\n",
    "metrics.extend(TopKs)\n",
    "\n",
    "f1 = tfa.metrics.F1Score(num_classes=classes, threshold=0.5)\n",
    "metrics.append(f1)\n",
    "\n",
    "# Optimizer\n",
    "# very average Adam settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "# compile it all\n",
    "enet.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 2785s 116s/step - loss: 0.0000e+00 - acc: 0.0486 - top_1: 0.0486 - top_5: 0.2740 - top_10: 0.5246 - top_20: 0.7590 - f1_score: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0510 - val_top_1: 0.0510 - val_top_5: 0.1655 - val_top_10: 0.6753 - val_top_20: 1.0000 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 2658s 111s/step - loss: 0.0000e+00 - acc: 0.0110 - top_1: 0.0110 - top_5: 0.3919 - top_10: 0.7466 - top_20: 0.8775 - f1_score: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.1862 - val_top_1: 0.1862 - val_top_5: 0.9968 - val_top_10: 0.9998 - val_top_20: 1.0000 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 3194s 135s/step - loss: 0.0000e+00 - acc: 0.0113 - top_1: 0.0113 - top_5: 0.3836 - top_10: 0.8582 - top_20: 0.9627 - f1_score: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00 - val_top_1: 0.0000e+00 - val_top_5: 0.0045 - val_top_10: 0.9128 - val_top_20: 1.0000 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 3289s 137s/step - loss: 0.0000e+00 - acc: 0.0130 - top_1: 0.0130 - top_5: 0.3651 - top_10: 0.8696 - top_20: 0.9771 - f1_score: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00 - val_top_1: 0.0000e+00 - val_top_5: 0.0020 - val_top_10: 0.2111 - val_top_20: 0.8761 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 3216s 134s/step - loss: 0.0000e+00 - acc: 0.0086 - top_1: 0.0086 - top_5: 0.4519 - top_10: 0.8646 - top_20: 0.9733 - f1_score: 0.0000e+00 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00 - val_top_1: 0.0000e+00 - val_top_5: 0.0000e+00 - val_top_10: 0.0574 - val_top_20: 0.9618 - val_f1_score: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = enet.fit(x=images,y=labels_onehot,validation_split=.20, epochs=5,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: ./checkpoints/enet_2022-05-03_01-47\n"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "checkpoint_time = '{date:%Y-%m-%d_%H-%M}'.format(date=datetime.datetime.now())\n",
    "\n",
    "save_file = './checkpoints/enet_{}'.format(checkpoint_time)\n",
    "print('Saving to:',save_file)\n",
    "enet.save_weights(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet.save('models/enet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed them into a feedforward network after efficient net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-load model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model('models/enet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allgood = np.testing.assert_allclose(enet.predict(X_), reconstructed_model.predict(X_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allgood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(y_true=Y, y_pred=y_pred, labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(Y_train, y_pred)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
