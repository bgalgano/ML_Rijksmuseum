{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CQoTKaPKpVE"
   },
   "source": [
    "Generate encoded vectors for both query and artist aggregrate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "QNV-EKWPKpVG",
    "outputId": "817b0f09-3a5b-49fe-8c31-2679bf2ee0e2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'read_rijksdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b7db8de1cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mread_rijksdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'read_rijksdata'"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "MIN_NUM_ARTWORK = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPuvAGpNKpVH",
    "outputId": "21239034-94ec-4ff9-941f-bf54816ed163"
   },
   "outputs": [],
   "source": [
    "# LOAD IMAGE AND LABELS HERE\n",
    "# replace for your path here!\n",
    "img_folder = '/Users/erebor/Downloads/out_img'\n",
    "\n",
    "images, labels_onehot, labels, names, = dataset.load_data(MIN_NUM_ARTWORK=MIN_NUM_ARTWORK,\n",
    "                                                 img_folder = img_folder,\n",
    "                                                 labels_file ='labels.txt',\n",
    "                                                 names_file = 'names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqj7rojzdkS6",
    "outputId": "21239034-94ec-4ff9-941f-bf54816ed163"
   },
   "outputs": [],
   "source": [
    "classes = len(list(set(labels)))\n",
    "print('\\n# of unique artists:',classes)\n",
    "\n",
    "counts = pd.DataFrame(labels).value_counts()\n",
    "print('Min # of artworks for all artists:',min(counts))\n",
    "print('Min # of artworks specified:',MIN_NUM_ARTWORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emVEhfBlKpVI"
   },
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED ENCODER\n",
    "# get base pre-trained model first\n",
    "# more models are available here: https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "\n",
    "# define hyperparameters\n",
    "# define image size \n",
    "input_shape = (56,56,3)\n",
    "D = 50\n",
    "# define number of classes\n",
    "# ****THIS sets the number of dimensions of the encoded vector (\"D\") in Mark's email***\n",
    "# we'll probably want adjust this to be smaller or larger (depending on training results)\n",
    "# for now, classes are just the number of unique artist\n",
    "base_kwargs = {'include_top':False,\n",
    "               'weights':'imagenet',\n",
    "               'input_shape':input_shape,\n",
    "               'pooling':None,\n",
    "               'classes':D}\n",
    "#enet_base = tf.keras.applications.efficientnet.EfficientNetB7(**enet_kwargs)\n",
    "base = tf.keras.applications.vgg19.VGG19(**base_kwargs)\n",
    "\n",
    "# set that the encoder DOES NOT train on the images\n",
    "base.trainable = True\n",
    "\n",
    "# set pre-trained model as base\n",
    "encoder = tf.keras.models.Sequential()\n",
    "encoder.add(base)\n",
    "\n",
    "# add two final top layers\n",
    "#encoder.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "encoder.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "#encoder.add(tf.keras.layers.Dropout(rate=0.01))\n",
    "\n",
    "encoder.add(tf.keras.layers.Dense(D, activation=\"sigmoid\")) # last (top) layer of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fe9On_u5KpVI",
    "outputId": "db80e953-37f0-4269-ce5e-0086840332d3"
   },
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "mHrCtb3ldkS7"
   },
   "source": [
    "# loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False,\n",
    "                                               label_smoothing=0.0,\n",
    "                                               name='categorical_crossentropy')\n",
    "\n",
    "# metrics\n",
    "\n",
    "TopKs = []\n",
    "for k in [1,5,10,20]:\n",
    "    TopK = tf.keras.metrics.TopKCategoricalAccuracy(k=k, name='top_{}'.format(k))\n",
    "    TopKs.append(TopK)\n",
    "metrics = [\"acc\"]\n",
    "metrics.extend(TopKs)\n",
    "\n",
    "f1 = tfa.metrics.F1Score(num_classes=classes, threshold=0.5)\n",
    "metrics.append(f1)\n",
    "\n",
    "# Optimizer\n",
    "# very average Adam settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "# compile it all\n",
    "encoder.compile(loss=loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics=metrics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "ugupgttpdkS8"
   },
   "source": [
    "history = encoder.fit(x=images,y=labels_onehot,validation_split=.20, epochs=2,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bUIq4OgKpVJ",
    "outputId": "214a0eb1-e278-4adf-c19d-f796351ab67b"
   },
   "outputs": [],
   "source": [
    "# Create encoded tensors for all \n",
    "vectors = encoder.predict(images,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTlHKvTJdkS8",
    "outputId": "f45b845f-9148-49fc-bb58-bce12cc7704c"
   },
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmvzGkAedkS9"
   },
   "outputs": [],
   "source": [
    "def plot_images(images,artistname):\n",
    "\n",
    "    # plot a selection of 25 (5x5) artwork\n",
    "    fig, axes = plt.subplots(figsize=(10,10),nrows=5,ncols=5)\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    i = 0 \n",
    "    for ax in axes.reshape(-1): \n",
    "        ax.imshow(images[i,:,:,:])\n",
    "        ax.set_xticks([]),ax.set_yticks([])\n",
    "        i +=1\n",
    "    plt.suptitle('Artist: {}'.format(artistname),fontsize=15)\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.savefig('figs/samples/artist_{}.png'.format(artistname[0].replace(',','-').replace(' ','-')),dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDjJtZGYKpVJ"
   },
   "outputs": [],
   "source": [
    "def get_aggregrate_vectors(vectors,labels):\n",
    "    # Create aggregate vectors\n",
    "    # Count how many pieces each artist has\n",
    "    total_bc = np.bincount(labels) # get count of artists\n",
    "    artcounts = total_bc[np.unique(labels)] # get count of artworks for each unique artist\n",
    "    artistnames = names[np.unique(labels)] # get the name for each unique artist\n",
    "\n",
    "    aggregate_vectors = []\n",
    "    for i in range(len(artcounts)):\n",
    "        artistnum = np.unique(labels)[i] #Gets the number that represents this artist from labels\n",
    "        artistname = artistnames[i]\n",
    "        artcount = artcounts[i] #Gets number of art pieces by this artist\n",
    "\n",
    "        neg_idx = np.where(labels != artistnum) \n",
    "        pos_idx = np.where(labels == artistnum)\n",
    "        artist_vector = np.mean(vectors[pos_idx],axis=0)\n",
    "\n",
    "        query_images = images[neg_idx]\n",
    "        query_vectors = vectors[neg_idx]\n",
    "\n",
    "        aggregate_vectors.append(artist_vector)\n",
    "\n",
    "        #x = np.expand_dims(vectors[pos_idx].T,axis=2)\n",
    "        #artist_vector = pool_layer(x).numpy()\n",
    "        #aggregate_vectors.append(artist_vector.reshape(50,))\n",
    "    aggregate_vectors = np.array(aggregate_vectors)\n",
    "    \n",
    "    return aggregate_vectors, artistnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IopvC5J1dkS-"
   },
   "outputs": [],
   "source": [
    "def plot_aggregates(aggregate_vectors,artistnames,n=3):\n",
    "    idx = list(range(aggregate_vectors.shape[0]))\n",
    "    idxs = np.random.choice(a=idx,size=n*n)\n",
    "    vectors = aggregate_vectors[idxs]\n",
    "    artists = artistnames[idxs]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n,ncols=n,figsize=(9,5))\n",
    "    for ax_idx, ax in enumerate(fig.axes):\n",
    "        norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "        ax.imshow(np.atleast_2d(vectors[ax_idx]), aspect=7, cmap='rainbow', interpolation=None,norm=norm)\n",
    "        ax.set_xticks([]),ax.set_yticks([])\n",
    "        ax.set_xlabel(artists[ax_idx][0])\n",
    "    plt.savefig('figs/aggregrates_sample_trained.png',dpi=200,tight_layout=True)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58d8e6NMdkS9",
    "outputId": "f5978b07-37b9-42dc-faac-e37b3465e883"
   },
   "outputs": [],
   "source": [
    "def plot_aggregate_dist(aggregate_vectors):\n",
    "    plt.figure()\n",
    "    bins = np.arange(0,1.1,0.05)\n",
    "    for vector in aggregate_vectors:\n",
    "        plt.hist(vector,bins=bins,alpha=0.25,histtype='bar')\n",
    "    plt.xlim(-0.05,1.05)\n",
    "    plt.show()\n",
    "    plt.title('Aggregrate Vectors')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phwd-3ySdkS-",
    "outputId": "8a48bd7e-3152-4fa5-a1ff-cf466fee489f"
   },
   "outputs": [],
   "source": [
    "aggregate_vectors, artistnames = get_aggregrate_vectors(vectors=vectors,labels=labels)\n",
    "plot_aggregates(aggregate_vectors,artistnames,n=4)\n",
    "plot_aggregate_dist(aggregate_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLEPypzrAvi5"
   },
   "outputs": [],
   "source": [
    "# Query Image Removal Function\n",
    "def query_image_remover(qi_vec, avg_vec, artnum):\n",
    "    new_vec = (avg_vec - (qi_vec * (1/artnum))) * (artnum/(artnum-1))\n",
    "    return new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19007, 50, 2)\n"
     ]
    }
   ],
   "source": [
    "NUM_EXAMPLE = 20\n",
    "train_val_split=0.8\n",
    "dev_split = 0.1\n",
    "\n",
    "total_bc = np.bincount(labels) # get count of artists\n",
    "artcounts = total_bc[np.unique(labels)] # get count of artworks for each unique artist\n",
    "artistnames = names[np.unique(labels)] # get the name for each unique artist\n",
    "\n",
    "aggregate_vectors = []\n",
    "artistnums = []\n",
    "# iterate through each artist\n",
    "for i in range(len(artcounts)):\n",
    "    artistnum = np.unique(labels)[i] # Gets the number that represents this artist from labels\n",
    "    artistnums.append(artistnum)\n",
    "    \n",
    "    artistname = artistnames[i] # Gets artist name as string\n",
    "    artcount = artcounts[i] # Gets number of art pieces by this artist\n",
    "\n",
    "    # get indicies of artist's artwork\n",
    "    pos_idx = np.where(labels == artistnum)\n",
    "\n",
    "    aggregate_vector = np.mean(vectors[pos_idx],axis=0)\n",
    "\n",
    "    # store aggregrate vectors for each artist\n",
    "    aggregate_vectors.append(aggregate_vector)\n",
    "\n",
    "\n",
    "aggregate_vectors = np.array(aggregate_vectors)\n",
    "\n",
    "# Generate pairs\n",
    "total_pairs = np.zeros(shape=(len(labels)*2,2))\n",
    "total_labels = np.zeros(shape=(len(labels)*2,1))\n",
    "\n",
    "j = 0\n",
    "for i in range(len(artcounts)):\n",
    "    artistnum = np.unique(labels)[i]\n",
    "    artcount = artcounts[i]\n",
    "\n",
    "    #Retreiving negative and positive indices\n",
    "    pos_idx = np.where(labels == artistnum)[0]\n",
    "    neg_idx = np.where(labels != artistnum)[0]\n",
    "\n",
    "\n",
    "    #Adding Positive Pairs for a given artist\n",
    "    for idx in pos_idx:\n",
    "        #print('j:',j)\n",
    "        #print('total pairs:', total_pairs)\n",
    "        #print('idx:',idx)\n",
    "        #print('artistnum:',artistnum)\n",
    "        total_pairs[j,:] = [idx,artistnum]\n",
    "        total_labels[j] = 1\n",
    "        j = j + 1\n",
    "\n",
    "    #Adding Negative Pairs for a given artist\n",
    "    neg_selec = np.random.choice(neg_idx,artcount,replace=False)\n",
    "    for idx in neg_selec:\n",
    "        total_pairs[j,:] = [idx,artistnum]\n",
    "        total_labels[j] = 0\n",
    "        j = j + 1\n",
    "\n",
    "# Create and Test Split Order\n",
    "goodbalance = False\n",
    "spltest_labels = labels\n",
    "\n",
    "while goodbalance == False:\n",
    "\n",
    "    #Shuffle data\n",
    "    mixer = np.arange(len(labels))\n",
    "    np.random.shuffle(mixer)\n",
    "    total_pairs = total_pairs[mixer,:]\n",
    "    total_labels = total_labels[mixer]\n",
    "\n",
    "    #Make Cutoffs\n",
    "    train_cutoff = int(len(total_pairs) * train_val_split)\n",
    "    dev_cutoff = int(len(total_pairs) * (train_val_split + dev_split))\n",
    "\n",
    "    #Test Splits for Balance\n",
    "    spltest_labels = spltest_labels[mixer]\n",
    "    train_spltest = spltest_labels[:train_cutoff]\n",
    "    dev_spltest = spltest_labels[train_cutoff:dev_cutoff]\n",
    "    val_spltest = spltest_labels[dev_cutoff:]\n",
    "\n",
    "    train_bc = np.bincount(train_spltest)\n",
    "    dev_bc = np.bincount(dev_spltest)\n",
    "    val_bc = np.bincount(val_spltest)\n",
    "\n",
    "    check_bool = np.array([],dtype=bool)\n",
    "\n",
    "    for i in np.unique(labels):\n",
    "        if (len(np.unique(spltest_labels)) == len(np.unique(train_spltest))) and (len(np.unique(spltest_labels)) == len(np.unique(dev_spltest))) and (len(np.unique(spltest_labels)) == len(np.unique(train_spltest))):\n",
    "            train_check = abs(total_bc[i]*0.8 - train_bc[i]) >= total_bc[i]*0.2 \n",
    "            dev_check = abs(total_bc[i]*0.1 - dev_bc[i]) >= total_bc[i]*0.08\n",
    "            val_check = abs(total_bc[i]*0.1 - val_bc[i]) >= total_bc[i]*0.08 \n",
    "            check_bool = np.append(check_bool,(train_check or dev_check or val_check))\n",
    "\n",
    "        elif total_bc[i] != 0:\n",
    "            check_bool = np.append(check_bool,False)\n",
    "\n",
    "    if sum(check_bool) <= 0:\n",
    "        goodbalance = True\n",
    "\n",
    "# Turn Pairs of Indices into Pairs of Vectors\n",
    "final_pairs = []\n",
    "for total_pair in enumerate(total_pairs):\n",
    "    \n",
    "    # get query vector index\n",
    "    vector_idx = int(total_pair[0])\n",
    "    \n",
    "    # get aggregrate index  \n",
    "    aggregrate_idx = np.where(artistnums==total_pair[-1])[0][0]\n",
    "\n",
    "    # get vectors\n",
    "    aggregrate_vector = aggregate_vectors[aggregrate_idx]\n",
    "    query_vector = vectors[vector_idx]\n",
    "\n",
    "    # save to array\n",
    "    final_pair = np.array([aggregrate_vector,query_vector]).T\n",
    "    final_pairs.append(final_pair)\n",
    "\n",
    "final_pairs = np.array(final_pairs)\n",
    "print(final_pairs.shape)\n",
    "# set aggregrate and query image pairs and labels into different\n",
    "train_pairs = final_pairs[:train_cutoff,:,:]\n",
    "train_labels = total_labels[:train_cutoff]\n",
    "\n",
    "dev_pairs = final_pairs[train_cutoff:dev_cutoff,:,:]\n",
    "dev_labels = total_labels[train_cutoff:dev_cutoff]\n",
    "\n",
    "val_pairs = final_pairs[dev_cutoff:,:,:]\n",
    "val_labels = total_labels[dev_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 631,  685,  912,  993, 1244, 1981, 2107, 2193, 2272, 2724, 2784,\n",
       "       2819, 3537, 3718, 3849, 3981, 4682, 4766, 5004, 5247, 6217])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 631.,  685.,  912.,  993., 1244., 1981., 2107., 2193., 2272.,\n",
       "       2724., 2784., 2819.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(total_pairs[:,1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "AcPeTwwcdkS_"
   },
   "source": [
    "def load_vectors(vectors, names, labels, NUM_EXAMPLE = 20, train_val_split=0.8, dev_split = 0.1):\n",
    "    \"\"\"\n",
    "    purpose: load dataset of query and aggregrate vector pairs and binary label indicating same artist among the pair\n",
    "        - label for each pair should be 1 if query vector and aggregrate vector belong to same artist, 0 if not\n",
    "        - any query vector that DOES belong to the artist should be subracted from aggregrate vector\n",
    "        - train, development, and validation are exclusive (no query image appear more than once)\n",
    "\n",
    "    arguments: \n",
    "        vectors (numpy matrix)    : all vectors that were encoded from images of original dataset\n",
    "        names  (list of strings)  : string for name of artist\n",
    "        labels (list of integers) : integer index of artist\n",
    "        NUM_EXAMPLE (integer)     : number of positive and negative pairs to create \n",
    "                                    e.g. total number of examples per artist is 2 * NUM_EXAMPLE\n",
    "                                    NUM_EXAMPLE should NOT be g\n",
    "    \n",
    "    returns:\n",
    "        train_pairs  : (batch, vector_length, 2) aggregrate and query image pairs for training\n",
    "        train_labels : (batch, )                 labels (0 or 1) indicating artist match for training\n",
    "        dev_pairs    : (batch, vector_length, 2) aggregrate and query image pairs for development\n",
    "        dev_labels   : (batch, )                 labels (0 or 1) indicating artist match for development\n",
    "        val_pairs    : (batch, vector_length, 2) aggregrate and query image pairs for validation\n",
    "        val_labels   : (batch, )                 labels (0 or 1) indicating artist match for validation\n",
    "    \"\"\"\n",
    "    total_bc = np.bincount(labels) # get count of artists\n",
    "    artcounts = total_bc[np.unique(labels)] # get count of artworks for each unique artist\n",
    "    artistnames = names[np.unique(labels)] # get the name for each unique artist\n",
    "    \n",
    "    aggregate_vectors = []\n",
    "    # iterate through each artist\n",
    "    for i in range(len(artcounts)):\n",
    "        artistnum = np.unique(labels)[i] # Gets the number that represents this artist from labels\n",
    "        artistname = artistnames[i] # Gets artist name as string\n",
    "        artcount = artcounts[i] # Gets number of art pieces by this artist\n",
    "\n",
    "        # get indicies of artist's artwork\n",
    "        pos_idx = np.where(labels == artistnum)\n",
    "               \n",
    "        aggregate_vector = np.mean(vectors[pos_idx],axis=0)\n",
    "        \n",
    "        # store aggregrate vectors for each artist\n",
    "        aggregate_vectors.append(aggregate_vector)\n",
    "\n",
    "    aggregate_vectors = np.array(aggregate_vectors)\n",
    "\n",
    "    # Generate pairs\n",
    "    total_pairs = np.zeros(shape=(len(labels)*2,2))\n",
    "    total_labels = np.zeros(shape=(len(labels)*2,1))\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(len(artcounts)):\n",
    "        artistnum = np.unique(labels)[i]\n",
    "        artcount = artcounts[i]\n",
    "\n",
    "        #Retreiving negative and positive indices\n",
    "        pos_idx = np.where(labels == artistnum)[0]\n",
    "        neg_idx = np.where(labels != artistnum)[0]\n",
    "\n",
    "        #Adding Positive Pairs for a given artist\n",
    "        for idx in pos_idx:\n",
    "            #print('j:',j)\n",
    "            #print('total pairs:', total_pairs)\n",
    "            #print('idx:',idx)\n",
    "            #print('artistnum:',artistnum)\n",
    "            total_pairs[j,:] = [idx,artistnum]\n",
    "            total_labels[j] = 1\n",
    "            j = j + 1\n",
    "\n",
    "        \n",
    "        #Adding Negative Pairs for a given artist\n",
    "        neg_selec = np.random.choice(neg_idx,artcount,replace=False)\n",
    "        for idx in neg_selec:\n",
    "            total_pairs[j,:] = [idx,artistnum]\n",
    "            total_labels[j] = 0\n",
    "            j = j + 1\n",
    "\n",
    "    # Create and Test Split Order\n",
    "    goodbalance = False\n",
    "    spltest_labels = labels\n",
    "\n",
    "    while goodbalance == False:\n",
    "\n",
    "        #Shuffle data\n",
    "        mixer = np.arange(len(labels))\n",
    "        np.random.shuffle(mixer)\n",
    "        total_pairs = total_pairs[mixer,:]\n",
    "        total_labels = total_labels[mixer]\n",
    "\n",
    "        #Make Cutoffs\n",
    "        train_cutoff = int(len(total_pairs) * train_val_split)\n",
    "        dev_cutoff = int(len(total_pairs) * (train_val_split + dev_split))\n",
    "\n",
    "        #Test Splits for Balance\n",
    "        spltest_labels = spltest_labels[mixer]\n",
    "        train_spltest = spltest_labels[:train_cutoff]\n",
    "        dev_spltest = spltest_labels[train_cutoff:dev_cutoff]\n",
    "        val_spltest = spltest_labels[dev_cutoff:]\n",
    "\n",
    "        train_bc = np.bincount(train_spltest)\n",
    "        dev_bc = np.bincount(dev_spltest)\n",
    "        val_bc = np.bincount(val_spltest)\n",
    "\n",
    "        check_bool = np.array([],dtype=bool)\n",
    "\n",
    "        for i in np.unique(labels):\n",
    "            if (len(np.unique(spltest_labels)) == len(np.unique(train_spltest))) and (len(np.unique(spltest_labels)) == len(np.unique(dev_spltest))) and (len(np.unique(spltest_labels)) == len(np.unique(train_spltest))):\n",
    "                train_check = abs(total_bc[i]*0.8 - train_bc[i]) >= total_bc[i]*0.2 \n",
    "                dev_check = abs(total_bc[i]*0.1 - dev_bc[i]) >= total_bc[i]*0.08\n",
    "                val_check = abs(total_bc[i]*0.1 - val_bc[i]) >= total_bc[i]*0.08 \n",
    "                check_bool = np.append(check_bool,(train_check or dev_check or val_check))\n",
    "\n",
    "            elif total_bc[i] != 0:\n",
    "                check_bool = np.append(check_bool,False)\n",
    "\n",
    "        if sum(check_bool) <= 0:\n",
    "            goodbalance = True\n",
    "\n",
    "\n",
    "    # Turn Pairs of Indices into Pairs of Vectors\n",
    "    for i in range(len(labels)*2):\n",
    "\n",
    "        k = np.where(np.unique(labels) == int(total_pairs[i,1]))[0]\n",
    "        print('\\nnp.unique(labels):\\n',np.unique(labels))\n",
    "        print('\\nint(total_pairs[i,1]):', int(total_pairs[i,1]))\n",
    "        print('\\nnp.where(np.unique(labels) == int(total_pairs[i,1]))[0]:',np.where(np.unique(labels) == int(total_pairs[i,1]))[0])\n",
    "        print('\\nk:',k)\n",
    "        print('\\nnp.unique(total_pairs[:,1]):\\t',np.unique(total_pairs[:,1]))\n",
    "        total_pairs[i,:] = [vectors[int(total_pairs[i,0])],aggregate_vectors[int(total_pairs[k,1])]]\n",
    "\n",
    "    # Split Pairs x\n",
    "    train_pairs = total_pairs[:train_cutoff,:,:]\n",
    "    train_labels = total_labels[:train_cutoff]\n",
    "\n",
    "    dev_pairs = total_pairs[train_cutoff:dev_cutoff,:,:]\n",
    "    dev_labels = total_labels[train_cutoff:dev_cutoff]\n",
    "\n",
    "    val_pairs = total_pairs[dev_cutoff:,:,:]\n",
    "    val_labels = total_labels[dev_cutoff:]\n",
    "\n",
    "    return train_pairs, train_labels, dev_pairs, dev_labels, val_pairs, val_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "r1iC46j2dkS_"
   },
   "source": [
    "train_pairs, train_labels, dev_pairs, dev_labels, val_pairs, val_labels = \\\n",
    "    load_vectors(vectors=vectors, names=names, labels=labels, NUM_EXAMPLE = 20, train_val_split=0.8, dev_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av8IKcT_dkS_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "make_vectors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
