{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate encoded vectors for both query and artist aggregrate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import read_rijksdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "MIN_NUM_ARTWORK = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |███████████████████████████████████████-| 112038/112039 \n",
      "\n",
      "Dataset loaded!\n",
      "images shape: (29703, 56, 56, 3)\n",
      "labels shape: (29703,)\n",
      "labels (one-hot): (29703, 50)\n",
      "names shape: (29703, 1)\n",
      "\n",
      "# of classes: 50\n",
      "Min # of artworks for all artists: 303\n",
      "Min # of artworks specified: 300\n"
     ]
    }
   ],
   "source": [
    "# LOAD IMAGE AND LABELS HERE\n",
    "# replace for your path here!\n",
    "img_folder = '/Users/erebor/Downloads/out_img'\n",
    "\n",
    "images, labels_onehot, labels, names = read_rijksdata.load_data(MIN_NUM_ARTWORK=MIN_NUM_ARTWORK,\n",
    "                                                 img_folder = img_folder,\n",
    "                                                 labels_file ='labels.txt',\n",
    "                                                 names_file = 'names.txt')\n",
    "\n",
    "classes = len(list(set(labels)))\n",
    "print('\\n# of classes:',classes)\n",
    "\n",
    "counts = pd.DataFrame(labels).value_counts()\n",
    "print('Min # of artworks for all artists:',min(counts))\n",
    "print('Min # of artworks specified:',MIN_NUM_ARTWORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED ENCODER\n",
    "# get base pre-trained model first\n",
    "# more models are available here: https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "\n",
    "# define hyperparameters\n",
    "# define image size \n",
    "input_shape = (56,56,3)\n",
    "\n",
    "# define number of classes\n",
    "# ****THIS sets the number of dimensions of the encoded vector (D) in Mark's email***\n",
    "# we'll probably want adjust this to be smaller or larger (depending on training results)\n",
    "# for now, classes are just the number of unique artist\n",
    "classes = len(list(set(labels)))\n",
    "enet_kwargs = {'include_top':False,\n",
    "               'weights':'imagenet',\n",
    "               'input_tensor':None,\n",
    "               'input_shape':input_shape,\n",
    "               'pooling':None,\n",
    "               'classes':classes,\n",
    "               'classifier_activation':'softmax'}\n",
    "enet_base = tf.keras.applications.efficientnet.EfficientNetB7(**enet_kwargs)\n",
    "\n",
    "# set that the encoder DOES NOT train on the images\n",
    "enet_base.trainable = False\n",
    "\n",
    "# set pre-trained model as base\n",
    "enet = tf.keras.models.Sequential()\n",
    "enet.add(enet_base)\n",
    "\n",
    "# add two final top layers\n",
    "enet.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "enet.add(tf.keras.layers.Dense(classes, activation=\"softmax\")) # last (top) layer of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb7 (Functional)  (None, 2, 2, 2560)        64097687  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                128050    \n",
      "=================================================================\n",
      "Total params: 64,225,737\n",
      "Trainable params: 128,050\n",
      "Non-trainable params: 64,097,687\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to generate vectors, just ask model to predict with the current loaded pre-trained model\n",
    "# to generate a vector for a single image:\n",
    "vector = enet.predict(image) # 1-D vector is of length D\n",
    "\n",
    "\n",
    "# load K number of artworks belong to an artist as a 4D array (K,length,width,channels)\n",
    "images =\n",
    "\n",
    "\n",
    "# iterate through artist's works to generate an aggregate vector\n",
    "vector_arr = []\n",
    "for image in images:\n",
    "    vector = enet.predict(image)\n",
    "    vector_arr.append(vector)\n",
    "    \n",
    "# not sure if this line is right, but something like this:\n",
    "# should go back to 1-D vector with length D, e.g. \"classes\"\n",
    "vector_aggregate = np.mean(vector_arr,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
