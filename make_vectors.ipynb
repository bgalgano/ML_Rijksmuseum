{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CQoTKaPKpVE"
   },
   "source": [
    "Generate encoded vectors for both query and artist aggregrate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QNV-EKWPKpVG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.1 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import read_rijksdata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa \n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "MIN_NUM_ARTWORK = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cPuvAGpNKpVH",
    "outputId": "21239034-94ec-4ff9-941f-bf54816ed163"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erebor/repos/ML_Rijksmuseum/read_rijksdata.py:22: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  names = pd.read_csv(names_file,delimiter = '/t',header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |███████████████████████████████████████-| 112038/112039 \n",
      "\n",
      "Dataset loaded!\n",
      "images shape:\t (19007, 56, 56, 3)\n",
      "labels shape:\t (19007,)\n",
      "labels (one-hot): (19007, 21)\n",
      "names shape:\t (19007, 1)\n"
     ]
    }
   ],
   "source": [
    "# LOAD IMAGE AND LABELS HERE\n",
    "# replace for your path here!\n",
    "img_folder = '/Users/erebor/Downloads/out_img'\n",
    "\n",
    "images, labels_onehot, labels, names, = read_rijksdata.load_data(MIN_NUM_ARTWORK=MIN_NUM_ARTWORK,\n",
    "                                                 img_folder = img_folder,\n",
    "                                                 labels_file ='labels.txt',\n",
    "                                                 names_file = 'names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cPuvAGpNKpVH",
    "outputId": "21239034-94ec-4ff9-941f-bf54816ed163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# of unique artists: 21\n",
      "Min # of artworks for all artists: 517\n",
      "Min # of artworks specified: 500\n"
     ]
    }
   ],
   "source": [
    "classes = len(list(set(labels)))\n",
    "print('\\n# of unique artists:',classes)\n",
    "\n",
    "counts = pd.DataFrame(labels).value_counts()\n",
    "print('Min # of artworks for all artists:',min(counts))\n",
    "print('Min # of artworks specified:',MIN_NUM_ARTWORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "emVEhfBlKpVI"
   },
   "outputs": [],
   "source": [
    "# LOAD PRE-TRAINED ENCODER\n",
    "# get base pre-trained model first\n",
    "# more models are available here: https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "\n",
    "# define hyperparameters\n",
    "# define image size \n",
    "input_shape = (56,56,3)\n",
    "vector_length = 50\n",
    "# define number of classes\n",
    "# ****THIS sets the number of dimensions of the encoded vector (\"D\") in Mark's email***\n",
    "# we'll probably want adjust this to be smaller or larger (depending on training results)\n",
    "# for now, classes are just the number of unique artist\n",
    "base_kwargs = {'include_top':False,\n",
    "               'weights':'imagenet',\n",
    "               'input_shape':input_shape,\n",
    "               'pooling':None,\n",
    "               'classes':vector_length}\n",
    "#enet_base = tf.keras.applications.efficientnet.EfficientNetB7(**enet_kwargs)\n",
    "base = tf.keras.applications.vgg19.VGG19(**base_kwargs)\n",
    "\n",
    "# set that the encoder DOES NOT train on the images\n",
    "base.trainable = True\n",
    "\n",
    "# set pre-trained model as base\n",
    "encoder = tf.keras.models.Sequential()\n",
    "encoder.add(base)\n",
    "\n",
    "# add two final top layers\n",
    "#encoder.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "encoder.add(tf.keras.layers.GlobalMaxPooling2D())\n",
    "#encoder.add(tf.keras.layers.Dropout(rate=0.01))\n",
    "\n",
    "encoder.add(tf.keras.layers.Dense(vector_length, activation=\"sigmoid\")) # last (top) layer of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Fe9On_u5KpVI",
    "outputId": "db80e953-37f0-4269-ce5e-0086840332d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                25650     \n",
      "=================================================================\n",
      "Total params: 20,050,034\n",
      "Trainable params: 20,050,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# loss function\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False,\n",
    "                                               label_smoothing=0.0,\n",
    "                                               name='categorical_crossentropy')\n",
    "\n",
    "# metrics\n",
    "\n",
    "TopKs = []\n",
    "for k in [1,5,10,20]:\n",
    "    TopK = tf.keras.metrics.TopKCategoricalAccuracy(k=k, name='top_{}'.format(k))\n",
    "    TopKs.append(TopK)\n",
    "metrics = [\"acc\"]\n",
    "metrics.extend(TopKs)\n",
    "\n",
    "f1 = tfa.metrics.F1Score(num_classes=classes, threshold=0.5)\n",
    "metrics.append(f1)\n",
    "\n",
    "# Optimizer\n",
    "# very average Adam settings\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "# compile it all\n",
    "encoder.compile(loss=loss,\n",
    "                optimizer=optimizer,\n",
    "                metrics=metrics)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history = encoder.fit(x=images,y=labels_onehot,validation_split=.20, epochs=2,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bUIq4OgKpVJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238/594 [===========>..................] - ETA: 4:24"
     ]
    }
   ],
   "source": [
    "# Create encoded tensors for all \n",
    "vectors = encoder.predict(images,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images,artistname):\n",
    "\n",
    "    # plot a selection of 25 (5x5) artwork\n",
    "    fig, axes = plt.subplots(figsize=(10,10),nrows=5,ncols=5)\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    i = 0 \n",
    "    for ax in axes.reshape(-1): \n",
    "        ax.imshow(images[i,:,:,:])\n",
    "        ax.set_xticks([]),ax.set_yticks([])\n",
    "        i +=1\n",
    "    plt.suptitle('Artist: {}'.format(artistname),fontsize=15)\n",
    "    fig.subplots_adjust(top=0.9)\n",
    "    plt.savefig('figs/samples/artist_{}.png'.format(artistname[0].replace(',','-').replace(' ','-')),dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDjJtZGYKpVJ"
   },
   "outputs": [],
   "source": [
    "# Create aggregate vectors\n",
    "# Count how many pieces each artist has\n",
    "total_bc = np.bincount(labels) # get count of artists\n",
    "artcounts = total_bc[np.unique(labels)] # get count of artworks for each unique artist\n",
    "artistnames = names[np.unique(labels)] # get the name for each unique artist\n",
    "\n",
    "aggregate_vectors = []\n",
    "for i in range(len(artcounts)):\n",
    "    artistnum = np.unique(labels)[i] #Gets the number that represents this artist from labels\n",
    "    artistname = artistnames[i]\n",
    "    artcount = artcounts[i] #Gets number of art pieces by this artist\n",
    "    \n",
    "    neg_idx = np.where(labels != artistnum) \n",
    "    pos_idx = np.where(labels == artistnum)\n",
    "    artist_vector = np.mean(vectors[pos_idx],axis=0)\n",
    "    \n",
    "    query_images = images[neg_idx]\n",
    "    query_vectors = vectors[neg_idx]\n",
    "    \n",
    "    aggregate_vectors.append(artist_vector)\n",
    "\n",
    "    #x = np.expand_dims(vectors[pos_idx].T,axis=2)\n",
    "    #artist_vector = pool_layer(x).numpy()\n",
    "    #aggregate_vectors.append(artist_vector.reshape(50,))\n",
    "      \n",
    "aggregate_vectors = np.array(aggregate_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bins = np.arange(0,1.1,0.05)\n",
    "for vector in aggregate_vectors:\n",
    "    plt.hist(vector,bins=bins,alpha=0.25,histtype='bar')\n",
    "plt.xlim(-0.05,1.05)\n",
    "plt.show()\n",
    "plt.title('Aggregrate Vectors Distributions')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aggregates(aggregate_vectors,artistnames,n=3):\n",
    "    idx = list(range(aggregate_vectors.shape[0]))\n",
    "    idxs = np.random.choice(a=idx,size=n*n)\n",
    "    vectors = aggregate_vectors[idxs]\n",
    "    artists = artistnames[idxs]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=n,ncols=n,figsize=(9,5))\n",
    "    for ax_idx, ax in enumerate(fig.axes):\n",
    "        norm = mpl.colors.Normalize(vmin=0, vmax=1)\n",
    "        ax.imshow(np.atleast_2d(vectors[ax_idx]), aspect=7, cmap='rainbow', interpolation=None,norm=norm)\n",
    "        ax.set_xticks([]),ax.set_yticks([])\n",
    "        ax.set_xlabel(artists[ax_idx][0])\n",
    "    plt.savefig('figs/aggregrates_sample_trained.png',dpi=200,tight_layout=True)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aggregates(aggregate_vectors,artistnames,n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1651784828485,
     "user": {
      "displayName": "Edward",
      "userId": "06390780441557377801"
     },
     "user_tz": 240
    },
    "id": "iLEPypzrAvi5"
   },
   "outputs": [],
   "source": [
    "# Query Image Removal Function\n",
    "def query_image_remover(qi_vec, avg_vec, artnum):\n",
    "    new_vec = (tf.math.subtract(avg_vec,  qi_vec * (1/artnum)) * (artnum/(artnum-1)))\n",
    "    return new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(vectors, names, labels, NUM_EXAMPLE = 20, train_val_split=0.8):\n",
    "    \"\"\"\n",
    "    purpose: load dataset of query and aggregrate vector pairs and binary label indicating same artist among the pair\n",
    "        - label for each pair should be 1 if query vector and aggregrate vector belong to same artist, 0 if not\n",
    "        - any query vector that DOES belong to the artist should be subracted from aggregrate vector\n",
    "        - train, development, and validation are exclusive (no query image appear more than once)\n",
    "\n",
    "    arguments: \n",
    "        vectors (numpy matrix)    : all vectors that were encoded from images of original dataset\n",
    "        names  (list of strings)  : string for name of artist\n",
    "        labels (list of integers) : integer index of artist\n",
    "        NUM_EXAMPLE (integer)     : number of positive and negative pairs to create \n",
    "                                    e.g. total number of examples per artist is 2 * NUM_EXAMPLE\n",
    "                                    NUM_EXAMPLE should NOT be greater than MIN_NUM_ARTWORK\n",
    "    \n",
    "    returns:\n",
    "        train_pairs  : (batch, vector_length, 2) aggregrate and query image pairs for training\n",
    "        train_labels : (batch, )                 labels (0 or 1) indicating artist match for training\n",
    "        dev_pairs    : (batch, vector_length, 2) aggregrate and query image pairs for development\n",
    "        dev_labels   : (batch, )                 labels (0 or 1) indicating artist match for development\n",
    "        val_pairs    : (batch, vector_length, 2) aggregrate and query image pairs for validation\n",
    "        val_labels   : (batch, )                 labels (0 or 1) indicating artist match for validation\n",
    "    \"\"\"\n",
    "    total_bc = np.bincount(labels) # get count of artists\n",
    "    artcounts = total_bc[np.unique(labels)] # get count of artworks for each unique artist\n",
    "    artistnames = names[np.unique(labels)] # get the name for each unique artist\n",
    "    \n",
    "    aggregate_vectors = []\n",
    "    query_vectors = []\n",
    "    used_query_idx = []\n",
    "    \n",
    "    # iterate through each artist\n",
    "    for i in range(len(artcounts)):\n",
    "        artistnum = np.unique(labels)[i] # Gets the number that represents this artist from labels\n",
    "        artistname = artistnames[i] # Gets artist name as string\n",
    "        artcount = artcounts[i] # Gets number of art pieces by this artist\n",
    "\n",
    "        # get indicies of artist's artwork\n",
    "        pos_idx = np.where(labels == artistnum)\n",
    "        \n",
    "        # get indicies that are not artist's artwork\n",
    "        neg_idx = np.where(labels != artistnum) \n",
    "\n",
    "        # get artwork vectors not belonging to artist\n",
    "        potential_query_vectors = vectors[neg_idx]\n",
    "        \n",
    "        aggregate_vector = np.mean(vectors[pos_idx],axis=0)\n",
    "        \n",
    "        # store aggregrate vectors for each artist\n",
    "        aggregate_vectors.append(artist_vector)\n",
    "\n",
    "    aggregate_vectors = np.array(aggregate_vectors)\n",
    "\n",
    "    return train_pairs, train_labels, dev_pairs, dev_labels, val_pairs, val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "make_vectors.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
